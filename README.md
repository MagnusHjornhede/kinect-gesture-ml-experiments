------------------------------------------------------------

Kinect Gesture ML Experiments — Experimental Stages 1–3

------------------------------------------------------------

This repository contains reports for a series of **experiments on Kinect skeleton gesture data**.
Each stage builds upon the same dataset (242 skeleton-derived numeric features + labels) and explores:  

- Stage 1: preprocessing, missing-data handling, exploratory analysis  
- Stage 2: training and evaluation of multiple baseline ML models  
- Stage 3: benchmarking the effect of PCA (95% variance) vs. using raw features  

The aim is to evaluate which models handle this type of gesture data best and to understand how preprocessing choices (like PCA) influence performance.  

------------------------------------------------------------
File Structure

------------------------------------------------------------

Stage 1

- stage1.py                Missing-data audit, imputation, scaling, visualization
- datasets/                Contains train-final.csv and test-final.csv  
- plots/                   Boxplots, heatmaps, histograms generated by task_1.py  

Stage 2

- stage2.py                Model zoo training, metrics, plots
- datasets/                Same CSVs  
- results/                 Metrics dumps in markdown format  

Stage 3

- stage3.py                 Main entry combining PCA vs non-PCA runs
- stage3_non_pca.py         Baseline runs without PCA  
- stage3_PCA.py             Baseline runs with PCA (95% variance retained)  
- plotting scripts         Plotting helpers for results  
- datasets/                Same CSVs  
- results/                 Comparisons and metrics  

------------------------------------------------------------
Dataset description

------------------------------------------------------------

- Origin: Kinect motion capture of human gestures  
- Features: 242 numeric values per sample, representing skeleton joint positions and motion-derived attributes  
- Labels:  
  • gesture name (categorical, human-readable)  
  • gesture ID (numeric code)  
- Format: CSV files without headers (headers are added in code as feature_1...feature_242 + labels)  
- Preprocessing: Missing values are imputed with column means, and features are standardized with Z-score scaling  
- Distribution: Contains multiple gesture classes, but class imbalance is present between training and test sets  

------------------------------------------------------------
Headline results

------------------------------------------------------------

- ExtraTrees and RandomForest perform best overall, consistently strong across runs  
- Linear SVM is a competitive baseline and especially strong after PCA  
- PCA (95%) helps linear models (SVM, Bagging) but hurts tree ensembles (RF,ExtraTrees)  
- Without PCA → tree ensembles dominate  
- With PCA → linear SVM achieves the best accuracy  

------------------------------------------------------------
Model insights

------------------------------------------------------------

- ExtraTrees / RandomForest  
  Excel because they handle high-dimensional tabular data with noisy/redundant features, selecting useful splits and averaging out noise  

- SVM (linear / rbf)  
  Effective on standardized numeric features; RBF captures nonlinearities, linear SVM benefits from PCA reducing redundancy  

- GradientBoosting / AdaBoost  
  Underperform without careful tuning due to sensitivity to noise and hyperparameters  

- Bagging  
  Improves weak learners’ stability (e.g. SVM-linear), especially with PCA, but still trails stronger ensembles  

- PCA effect  
  Helps linear models by reducing collinearity and redundancy, but harms tree ensembles that rely on original feature axes  

------------------------------------------------------------
Conclusions

------------------------------------------------------------

From these experiments we conclude:  

1. Tree ensembles are the most robust baseline for Kinect skeleton data without heavy preprocessing.
2. PCA shifts the advantage toward linear models by compressing feature space and reducing redundancy.
3. No single model dominates in all conditions — the best choice depends on preprocessing strategy.
4. For practical applications: RandomForest / ExtraTrees are reliable defaults, while SVM-linear + PCA is a strong alternative when interpretability and simplicity are important.

------------------------------------------------------------
